{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook solves a version of Krusell and Smith's (1998) heterogenous-agent model with idiosyncrastic and aggregate shocks, incomplete markets and borrowing constraints. It uses a deep learning Euler-equation method introduced by Maliar, Maliar and Winant (2018) in the paper \"Deep learning for solving dynamic economic models\", Journal of Monetary Economics 122, pp 76-101. https://lmaliar.ws.gc.cuny.edu/files/2021/09/JME2021.pdf\n",
    "\n",
    "This notebook shows a version of the Euler equation method that minimizes the sum of squared residuals in the equilibrium conditions. See https://deepecon.org for documentation, updates and the other versions of the deep learning method (Bellman equation and life-time reward). \n",
    "\n",
    "Copyright (c) 2019-2023 Marc Maliar. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version: 2.13.0-rc1\n"
     ]
    }
   ],
   "source": [
    "print('tf version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPU, uncomment if you want to use GPU\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENTS = 50     # number of agents\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAINING_STEPS = 30000\n",
    "BATCH_SIZE = 10\n",
    "DISPLAY_STEP = 1000\n",
    "TRAIN_STEP_INTERVAL = 2 # Interval of steps between training episodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krusell and Smith's (1998) model\n",
    "\n",
    "The economy consists of a set of heterogeneous agents $i=1,...,\\ell $ that\n",
    "are identical in fundamentals but differ in productivity and capital. Each\n",
    "agent $i$ solves \n",
    "\\begin{gather}\n",
    "\\underset{\\left \\{ c_{t}^{i},k_{t+1}^{i}\\right \\} _{t=0}^{\\infty }}{\\max }%\n",
    "E_{0}\\left[ \\sum_{t=0}^{\\infty }\\beta ^{t}u\\left( {c_{t}^{i}}\\right) \\right]\n",
    "\\label{iks} \\\\\n",
    "\\text{s.t. }w_{t+1}^{i}=\\left( R_{t+1}-d \\right) \\left( w_{t}^{i}-c_{t}^{i}\\right)\n",
    "+W_{t+1}\\exp \\left( y_{t+1}^{i}\\right) ,  \\label{sks} \\\\\n",
    "c_{t}^{i}\\leq w_{t}^{i},  \\label{rks}\n",
    "\\end{gather}\n",
    "where $\\beta_{t}$,$c_{t}^{i}$, $w_{t}^{i}$, $y_{t}^{i}$, $R_{t}$, $W_{t}$ and $%\n",
    "k_{t+1}^{i}=w_{t}^{i}-c_{t}^{i}$ are time preference, consumption, cash-on-hand, labor\n",
    "productivity, interest rate, wage and next-period capital, respectively. $d\\in\n",
    "\\left( 0,1\\right] $ is the depreciation rate.\n",
    "Initial condition $\\left( y_{0}^{i},w_{0}^{i}\\right) $ is given. The\n",
    "individual productivity evolves as \n",
    "\\begin{equation}\n",
    "y_{t+1}^{i}=\\rho _{y}y_{t}^{i}+\\sigma _{y}\\epsilon _{t}^{i}\\text{ with }\n",
    "\\epsilon _{t}^{i}\\sim \\mathcal{N}\\left( 0,1\\right) .  \\label{ip}\n",
    "\\end{equation}\n",
    "The production side of the economy is described by a Cobb-Douglas production\n",
    "function $z_{t}Ak_{t}^{\\alpha }\\left[ \\sum_{i=1}^{\\ell }\\exp \\left(\n",
    "y_{t}^{i}\\right) \\right]$, where A is technology level, $\\alpha \\in \\left( 0,1\\right) $ and $%\n",
    "z_{t}$ is an aggregate productivity shock, \n",
    "\\begin{equation}\n",
    "z_{t+1}=\\rho_{z} z_{t}+\\sigma_{z} \\epsilon _{t}\\text{ with }\\epsilon _{t}\\sim \n",
    "\\mathcal{N}\\left( 0,1\\right) .  \\label{za}\n",
    "\\end{equation}\n",
    "Initial condition $z_{0}$ is given. The equilibrium prices are\n",
    "\n",
    "\\begin{equation}\n",
    "R_{t}=\n",
    "1+z_{t}\\alpha Ak_{t}^{\\alpha -1}\\left[ \\sum_{i=1}^{\\ell}\\exp \\left(\n",
    "y_{t}^{i}\\right) \\right] \\text{ and }W_{t}=z_{t}\\left( 1-\\alpha \\right)A\n",
    "k_{t}^{\\alpha }\\left[ \\sum_{i=1}^{\\ell }\\exp \\left( y_{t}^{i}\\right) \\right],  \\label{rw} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where $k_{t}=\\sum_{i=1}^{\\ell }k_{t}^{i}$ is aggregate capita. Note that $w_{t}^{i}=R_{t}k_{t}^{i}+W_{t}\\exp \\left( y_{t}^{i}\\right) $. In the benchmark case, we\n",
    "parametrize the model by CRRA utiltiy function, $u\\left( c\\right) =\\frac{c^{1-\\gamma }-1}{1-\\gamma }\n",
    "$, with a risk-aversion coefficient of $\\gamma =1$. This means that the utility function is $u\\left( c\\right)=\\ln(c)$.\n",
    "We assume d=0.08, $\\beta =0.96$, $%\n",
    "\\rho_{z} =0.95$, $\\sigma_{z} =0.01$, $\\rho _{y}=0.9$, and $\\sigma _{y}=0.2\\left(\n",
    "1-\\rho _{y}^{2}\\right) ^{1/2}$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "α = 0.36   # share of capital in the Cobb-Douglas production function\n",
    "d = 0.08   # depreciation rate \n",
    "A = 1      # Technology level\n",
    "β = 0.96   # Time preferece/discount factor\n",
    "γ = 1      # parameter for risk aversion. CRRA utility function. \n",
    "d = 0.08\n",
    "\n",
    "mean_z = 0.0    # aggregate productivity shock\n",
    "ρ_z = 0.9    # persistency of aggregate productivity shock\n",
    "σ_z = 0.01   # standard deviation\n",
    "\n",
    "mean_y = 0.0 # idiosyncratic productivity shock\n",
    "ρ_y = 0.95   #persistency of idiosyncratic productivity shock\n",
    "σ_y = 0.2    # standard deviation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steady state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_STEADY_STATE = (((1/β)-(1-d))/α/A)**(1/(α-1))           # capital\n",
    "W_STEADY_STATE = K_STEADY_STATE*(1-d)+A*K_STEADY_STATE**α # wealth \n",
    "C_STEADY_STATE = A*K_STEADY_STATE**α-d*K_STEADY_STATE     # consumption\n",
    "ξ_STEADY_STATE = C_STEADY_STATE/W_STEADY_STATE            # consumption-to-wealth ratio, ksi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic solution domain\n",
    "\n",
    "Our economy has 2*AGENTS + 1 state variables, which are wealth and productivity of all agents and an aggregate productivity. Our DL framework solves the model on stochastic simulation (ergodic set). When simulating the model, we: \n",
    "- restrict aggregate and individual productivities $z, y$ to be within ± 2*standard deviations $\\frac{±\\sigma}{\\sqrt{1-\\rho^2}}$;\n",
    "- restrict $w$ to be within an interval: $w\\in[w_{\\min}, w_{\\max}]$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bounds on state variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds for aggregate productivity level\n",
    "z_min = math.exp(-2 * σ_z  / math.sqrt(1-ρ_z**2))\n",
    "z_max = math.exp(2 * σ_z  / math.sqrt(1-ρ_z**2))\n",
    "\n",
    "# Bounds for individual productivity level\n",
    "y_min = math.exp(-2 * σ_y  / math.sqrt(1-ρ_y**2))\n",
    "y_max = math.exp( 2 * σ_y  / math.sqrt(1-ρ_y**2))\n",
    "\n",
    "# Cash-on-hand's bounds\n",
    "w_min = 0.0*W_STEADY_STATE\n",
    "w_max = 4.0*W_STEADY_STATE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_across_agents(x):\n",
    "    return tf.reduce_mean(x, axis=1, keepdims=True)\n",
    "\n",
    "def consumption_capital(w, ξ):\n",
    "    c = w*ξ\n",
    "    kp = w*(1-ξ)                    # k' = next-period indovodual capital\n",
    "    kp = tf.math.minimum(kp, w_max) # if kp>W_HIGH, set kp=W_HIGH\n",
    "    c = w - kp                      # recompute c \n",
    "   \n",
    "    return c, kp\n",
    "\n",
    "def next_period(kp, yp, zp):\n",
    "    kp_aggregate = mean_across_agents(kp)\n",
    "    rp = A*zp*α*kp_aggregate**(α-1)      # next-period interest rate\n",
    "    wagep = A*zp*(1-α)*kp_aggregate**(α) # next-period wage\n",
    "    wp = (1-d+rp)*kp+wagep*yp            # individual next-period wealth\n",
    "    \n",
    "    return rp, wp\n",
    "\n",
    "def productivity_transition_to_next_period(y, z, εy, εz):\n",
    "    yp = y**ρ_y*tf.math.exp(εy)*math.exp((-0.5*(1-ρ_y)*σ_y**2)/(1-ρ_y**2))\n",
    "        # exp((-0.5*(1-ρ_y)*σ_y**2)/(1-ρ_y**2)) makes mean = 1\n",
    "    yp = tf.math.minimum(tf.math.maximum(yp, y_min), y_max)\n",
    "        # restrict the individual productivity to be within the bounds\n",
    "    yp = yp / mean_across_agents(yp)\n",
    "        # normalize future individual shocks so that they sum up to one \n",
    "    \n",
    "    zp = z**ρ_z*tf.math.exp(εz)*math.exp((-0.5*(1-ρ_z)*σ_z**2)/(1-ρ_z**2))\n",
    "    zp = tf.math.minimum(tf.math.maximum(zp, z_min), z_max)\n",
    "        # the same for aggregare productivity except of normalizing to one\n",
    "    return yp, zp \n",
    "\n",
    "def normalize_all(w, y, z):                                # normalize inputs for neural network\n",
    "    normw = (w - w_min) / (w_max-w_min)*2.0 - 1.0          # normalize to interval [-1,1]\n",
    "    normy = tf.math.log(y) / (2*σ_y / math.sqrt(1-ρ_y**2)) # normalize to ±2standard deviations to approximately fit to [-1,1]\n",
    "    normz = tf.math.log(z) / (2*σ_z / math.sqrt(1-ρ_z**2)) \n",
    "    \n",
    "    return normw, normy, normz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The neural-network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameterization of decision functions with neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parametrize the consumption to\n",
    "wealth ratio $\\frac{c_{t}^{i}}{w_{t}^{i}}$ and unit-free Lagrange multiplier $%\n",
    "h_{t}^{i}$:\n",
    "\\begin{eqnarray*}\n",
    "\\xi_t=\\frac{c_{t}^{i}}{w_{t}^{i}} &=&\\sigma \\left( \\zeta _{0}+\\eta \\left(\n",
    "y_{t}^{i},w_{t}^{i},D_{t},z_{t};\\vartheta \\right) \\right) \\equiv \\varphi\n",
    "\\left( \\cdot ;\\theta \\right), \\\\\n",
    "h_{t}^{i} &=&\\exp \\left( \\zeta _{0}+\\eta \\left(\n",
    "y_{t}^{i},w_{t}^{i},D_{t},z_{t};\\vartheta \\right) \\right) \\equiv h\\left(\n",
    "\\cdot ;\\theta \\right), \n",
    "\\end{eqnarray*}\n",
    "where $\\eta \\left( \\cdot ;\\vartheta \\right) $ is a neural network, $%\n",
    "D_{t}\\equiv \\left \\{ y_{t}^{i},w_{t}^{i}\\right \\} _{i=1}^{\\ell }$ is the\n",
    "distribution, $\\theta \\equiv \\left( \\zeta _{0},\\vartheta \\right) $ and $%\n",
    "\\sigma \\left( x\\right) =\\frac{1}{1+e^{-x}}$.\n",
    "\n",
    "A sigmoid transformation of $\\varphi \\left( \\cdot ;\\theta \\right) $ ensures\n",
    "that $\\frac{c_{t}^{i}}{w_{t}^{i}}$ is in the interval $\\left[ 0,1\\right] $;\n",
    "the exponentiation of $h_{t}$ ensures that it is nonnegative. The parameter $%\n",
    "\\zeta _{0}$s are calibrated; $\\zeta _{0}=logit(\\frac{c_{steady\\_state}}{w_{steady\\_state}})$ for $\\varphi\n",
    "\\left( \\cdot ;\\theta \\right)$ and $\\zeta _{0}=0$ for $h\\left(\n",
    "\\cdot ;\\theta \\right)$.\n",
    "The biases and weights are initialized\n",
    "randomly by using \"he\" and \"glorot\" uniform distributions,\n",
    "respectively. In the baseline case, we use a neural network with a sigmoid\n",
    "activation function and two hidden layers of $32\\times 32$ neurons."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = 2*AGENTS+3           # inputs consist of \n",
    "                                       # 2*AGENTS state variables of all agents \n",
    "                                       # 2 state variables of a given agent i (wealth and productivities)\n",
    "                                       # 1 aggregate productivity \n",
    "first_hidden_layer_neurons = 32\n",
    "second_hidden_layer_neurons = 32\n",
    "output_dimension = 2                   # ksi (share of consumption in wealth), multiplier (on the borrowing constraint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resulting layer shapes (weights and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hidden_layer_weights_shape = \\\n",
    "    (input_dimension,             first_hidden_layer_neurons)\n",
    "# E.g., with 10 agents and 4 neurons, it's 23-by-4, where input_dimension = 23 with 10 agents\n",
    "first_hidden_layer_biases_shape  = \\\n",
    "    (1,                           first_hidden_layer_neurons)\n",
    "\n",
    "second_hidden_layer_weights_shape = \\\n",
    "    (first_hidden_layer_neurons,  second_hidden_layer_neurons)\n",
    "# E.g., 4 neurons in each hidden leayer, it's 4-by-4\n",
    "second_hidden_layer_biases_shape  = \\\n",
    "    (1,                           second_hidden_layer_neurons)\n",
    "\n",
    "output_layer_weights_shape = \\\n",
    "    (second_hidden_layer_neurons, output_dimension)\n",
    "output_layer_biases_shape  = \\\n",
    "    (1,                           output_dimension)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the neural-network weights in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmaliar/src/deep-learning-euler-method-krusell-smith/venv/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Weights initializers\n",
    "he_normal_initializer = tf.keras.initializers.he_normal()\n",
    "zero_initializer = tf.keras.initializers.Constant(value=0.0)\n",
    "small_initializer = tf.keras.initializers.TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "\n",
    "first_hidden_layer_weights = \\\n",
    "    tf.compat.v1.get_variable(name = \"first_hidden_layer_weights\", \n",
    "                              shape=first_hidden_layer_weights_shape, \n",
    "                              initializer=small_initializer)\n",
    "\n",
    "first_hidden_layer_biases = \\\n",
    "    tf.compat.v1.get_variable(name = \"first_hidden_layer_biases\", \n",
    "                              shape=first_hidden_layer_biases_shape, \n",
    "                              initializer=zero_initializer)\n",
    "\n",
    "\n",
    "second_hidden_layer_weights = \\\n",
    "    tf.compat.v1.get_variable(name = \"second_hidden_layer_weights\", \n",
    "                              shape=second_hidden_layer_weights_shape, \n",
    "                              initializer=small_initializer)\n",
    "\n",
    "second_hidden_layer_biases = \\\n",
    "    tf.compat.v1.get_variable(name = \"second_hidden_layer_biases\", \n",
    "                              shape=second_hidden_layer_biases_shape, \n",
    "                              initializer=zero_initializer)\n",
    "\n",
    "output_layer_weights = \\\n",
    "    tf.compat.v1.get_variable(name = \"output_layer_weights\", \n",
    "                              shape=output_layer_weights_shape, \n",
    "                              initializer=small_initializer)\n",
    "\n",
    "output_layer_biases = \\\n",
    "    tf.compat.v1.get_variable(name = \"output_layer_biases\", \n",
    "                              shape=output_layer_biases_shape, \n",
    "                              initializer=zero_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_variables_list = [first_hidden_layer_weights, first_hidden_layer_biases, second_hidden_layer_weights, \\\n",
    "    second_hidden_layer_biases,output_layer_weights, output_layer_biases] # list of trainable neural network parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The neural-network function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(input_tensor):\n",
    "\n",
    "    first_hidden_layer_result = \\\n",
    "        tf.add(tf.matmul(input_tensor, first_hidden_layer_weights), first_hidden_layer_biases)\n",
    "    # The number of weights connecting inputs and the 1st hiddent layer is (2*AGENTS+3)-by-(first_hidden_layers_neurons); \n",
    "    # to the resulting number, we add biases\n",
    "    \n",
    "    first_hidden_layer_result_sigmoided = tf.nn.sigmoid(first_hidden_layer_result)\n",
    "    # Apply a sigmoid activation function\n",
    "\n",
    "    second_hidden_layer_result = \\\n",
    "        tf.add(tf.matmul(first_hidden_layer_result_sigmoided, second_hidden_layer_weights), second_hidden_layer_biases)\n",
    "    \n",
    "    second_hidden_layer_result_sigmoided = tf.nn.sigmoid(second_hidden_layer_result)\n",
    "    # Apply a sigmoid activation-function\n",
    "    \n",
    "    output_layer_result = \\\n",
    "        tf.add(tf.matmul(second_hidden_layer_result_sigmoided, output_layer_weights), output_layer_biases)\n",
    "    \n",
    "    # Don´t apply sigmoid to the last layer, we will do it later if necessary\n",
    "    \n",
    "    return output_layer_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN functions that produce decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_neural_network_for_all_agents_given_state(w, y, z):\n",
    "    \n",
    "    # Normalize the states used in the neural network\n",
    "    normw, normy, normz = normalize_all(w, y, z)\n",
    "\n",
    "    normw_unstacked = tf.unstack(normw, axis=1) # transform a 2D tensors into a list of 1D tensors\n",
    "    normy_unstacked = tf.unstack(normy, axis=1) # transform a 2D tensors into a list of 1D tensors\n",
    "        # 2D tensors are of size BATCH_SIZE-by-AGENTS\n",
    "    \n",
    "    dim_list = lambda l: list(map(lambda x: tf.expand_dims(x, axis=0), l))\n",
    "       \n",
    "    sum_information = dim_list(normw_unstacked+normy_unstacked)  # get the list of normalized w and y.\n",
    "    concat = [tf.concat(\n",
    "        sum_information+\n",
    "        [tf.transpose(normz, [1, 0]), \n",
    "        tf.expand_dims(normw_unstacked[i], 0), \n",
    "        tf.expand_dims(normy_unstacked[i], 0)], axis=0)\n",
    "              for i in range(AGENTS)]\n",
    "\n",
    "    stack = tf.stack(concat, axis=1) ## The column is for each agent\n",
    "    input_tensor = tf.reshape(tf.transpose(stack, perm=[2, 1, 0]), [-1, input_dimension]) \n",
    "        # Batches, agents, input\n",
    "    output_tensor = neural_network(input_tensor) ## so each output will be about each agent\n",
    "        # Batches, agents*output\n",
    "    \n",
    "    output_tensor_reshaped = tf.reshape(output_tensor, [-1, AGENTS, output_dimension])\n",
    "    \n",
    "    ξ_before_sigmoid, μ_before_exp = tf.unstack(output_tensor_reshaped, axis=2)\n",
    "    def logit(x):\n",
    "        return np.log(x/(1-x)) # Inverse of sigmoid\n",
    "    ξ = tf.sigmoid(ξ_before_sigmoid+logit(ξ_STEADY_STATE))  #KSI\n",
    "    μ = tf.exp(μ_before_exp)  # Lagrangian multiplier\n",
    "    \n",
    "    return ξ, μ\n",
    "        # given state variables, we get ksi (share of consumption in wealth), multiplier (on the borrowing constraint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model through a TensorFlow computational graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euler objective function for training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Euler objective function for Krusell and Smith's (1998) model is\n",
    "based on all-in-one expectation operator of two uncorrelated shocks (see the paper for a discussion of this technique): \n",
    "\\begin{multline}\n",
    "\\Xi (\\theta )=E_{\\omega }\\left[ \\xi \\left( \\omega ;\\theta \\right) \\right]\n",
    "=E_{\\left( Y_{t},W_{t},z_{t},\\Sigma _{1},\\Sigma _{2},\\epsilon _{1,},\\epsilon\n",
    "_{2}\\right) }\\left \\{ \\left[ \\Psi ^{FB}\\left( 1-\\frac{c_{t}^{i}}{w_{t}^{i}}%\n",
    ",1-h_{t}^{i}\\right) \\right] ^{2}\\right.  \\label{MC_2ks} \\\\\n",
    "\\left. +v\\left[ \\frac{\\beta R_{t+1}\\left. u^{\\prime }\\left(\n",
    "c_{t+1}^{i}\\right) \\right \\vert _{\\Sigma =\\Sigma _{1},\\epsilon =\\epsilon\n",
    "_{1}}}{u^{\\prime }\\left( c_{t}^{i}\\right) }-h_{t}^{i}\\right] \\left[ \\frac{%\n",
    "\\beta R_{t+1}\\left. u^{\\prime }\\left( c_{t+1}^{i}\\right) \\right \\vert\n",
    "_{\\Sigma =\\Sigma _{2},\\epsilon =\\epsilon _{2}}}{u^{\\prime }\\left(\n",
    "c_{t}^{i}\\right) }-h_{t}^{i}\\right] \\right \\},\n",
    "\\end{multline}\n",
    "where $\n",
    "Y_{t}=\\left( y_{t}^{1},...,y_{t}^{\\ell }\\right) $ and $W_{t}=\\left(\n",
    "w_{t}^{1},...,w_{t}^{\\ell }\\right) $ and $z_{t}$ are the economy's state\n",
    "produced stochastic simulation; $\\Sigma _{1}=\\left( \\epsilon\n",
    "_{1}^{1},...,\\epsilon _{1}^{\\ell }\\right) $, $\\Sigma _{2}=\\left( \\epsilon\n",
    "_{2}^{1},...,\\epsilon _{2}^{\\ell }\\right) $ are two uncorrelated random\n",
    "draws of individual productivity shocks; and $\\epsilon _{1,}$, $\\epsilon\n",
    "_{2} $ are two uncorrelated random draws for the aggregate productivity\n",
    "innovations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model functions to placeholder tensors to generate computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current time period\n",
    "@tf.function\n",
    "def run_model(w0, y0, z0, εy_a, εz_a, εy_b, εz_b):\n",
    "\n",
    "    ξ0, μ0 = run_neural_network_for_all_agents_given_state(w0, y0, z0)\n",
    "    c0, k1 = consumption_capital(w0, ξ0)\n",
    "\n",
    "    y1_a, z1_a = productivity_transition_to_next_period(y0, z0, εy_a, εz_a)\n",
    "    r1_a, w1_a = next_period(k1, y1_a, z1_a)\n",
    "    ξ1_a, μ1_a = run_neural_network_for_all_agents_given_state(w1_a, y1_a, z1_a)\n",
    "    c1_a, k2_a = consumption_capital(w1_a, ξ1_a)\n",
    "\n",
    "    y1_b, z1_b = productivity_transition_to_next_period(y0, z0, εy_b, εz_b)\n",
    "    r1_b, w1_b = next_period(k1, y1_b, z1_b)\n",
    "    ξ1_b, μ1_b = run_neural_network_for_all_agents_given_state(w1_b, y1_b, z1_b)\n",
    "    c1_b, k2_b = consumption_capital(w1_b, ξ1_b)\n",
    "    \n",
    "    # Error 1\n",
    "    R_μ = μ0 - 1\n",
    "    R_ξ = w0 / c0 - 1\n",
    "    R_μξ = R_μ+R_ξ-tf.math.sqrt(R_μ**2+R_ξ**2) # residual in the Fisher-Burmeister function; eq. (25) in MMV (2021)\n",
    "\n",
    "    # Error 2\n",
    "    R2_a = β*(c1_a**(-γ))*(1-d+r1_a)/(c0**(-γ))-μ0 # residual in the Euler equation under shock a \n",
    "    R2_b = β*(c1_b**(-γ))*(1-d+r1_b)/(c0**(-γ))-μ0 \n",
    "\n",
    "    Residual1 = tf.reduce_mean(R_μξ**2)\n",
    "    Residual2 = tf.reduce_mean(R2_a*R2_b)\n",
    "\n",
    "    # Mean squared errors\n",
    "    loss_op = Residual1 + Residual2\n",
    "    \n",
    "    return ξ0, μ0, c0, k1, y1_a, z1_a, r1_a, w1_a, ξ1_a, μ1_a, c1_a, k2_a, \\\n",
    "        y1_b, z1_b, r1_b, w1_b, ξ1_b, μ1_b, c1_b, k2_b, loss_op, Residual1, Residual2   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make empty loss-value vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vals = np.empty((TRAINING_STEPS, 1)) # Return a new array of size TRAINING_STEPS-by-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Define the optimization method to be used\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define group of tensors of train that we will compute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions used to generate shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_state(required_batch_size):\n",
    "    w = np.reshape(np.random.uniform(W_STEADY_STATE, W_STEADY_STATE, required_batch_size*AGENTS), \\\n",
    "                   (required_batch_size, AGENTS))\n",
    "    y = np.reshape(np.random.uniform(1, 1, required_batch_size*AGENTS), (required_batch_size, AGENTS))\n",
    "    z = np.reshape(np.random.uniform(1, 1, required_batch_size), (required_batch_size, 1))\n",
    "    w = tf.cast(w, dtype=tf.float32)\n",
    "    y = tf.cast(y, dtype=tf.float32)\n",
    "    z = tf.cast(z, dtype=tf.float32)\n",
    "    return w, y, z\n",
    "        # initial condition is taken in steady state\n",
    "    \n",
    "def generate_εy(required_batch_size):\n",
    "    return tf.cast(np.reshape(np.random.normal(mean_y, σ_y, required_batch_size*AGENTS), (required_batch_size, AGENTS)), dtype=tf.float32)\n",
    "        # generate shocks to y\n",
    "    \n",
    "def generate_εz(required_batch_size):\n",
    "    return tf.cast(np.reshape(np.random.normal(mean_z, σ_z, required_batch_size), (required_batch_size, 1)), dtype=tf.float32)\n",
    "        # generate shocks to z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at 0: 0.004082968458533287 (Residual1=0.0018734587356448174, Residual2=0.0022095099557191133)\n",
      "Training took 19.39037799835205 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Start timer\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# initial states\n",
    "w_train, y_train, z_train = initial_state(required_batch_size = BATCH_SIZE)\n",
    "# construct initial condition in the steady state\n",
    "\n",
    "for i in range(TRAINING_STEPS):\n",
    "    # Get 2 uncorrelated shocks for y and z\n",
    "    εy_a_train = generate_εy(BATCH_SIZE)\n",
    "    εy_b_train = generate_εy(BATCH_SIZE)\n",
    "    \n",
    "    εz_a_train = generate_εz(BATCH_SIZE)\n",
    "    εz_b_train = generate_εz(BATCH_SIZE)\n",
    "\n",
    "    # Train the model if the remainder of i/TRAIN_STEP_INTERVAL == 0\n",
    "    if i % TRAIN_STEP_INTERVAL == 0:\n",
    "        with tf.GradientTape() as tape:\n",
    "            ξ0, μ0, c0, k1, y1_a, z1_a, r1_a, w1_a, ξ1_a, μ1_a, c1_a, k2_a, \\\n",
    "                y1_b, z1_b, r1_b, w1_b, ξ1_b, μ1_b, c1_b, k2_b, loss_op , Residual1, Residual2 = \\\n",
    "            run_model(w0=w_train, y0=y_train, z0=z_train, εy_a=εy_a_train, εy_b=εy_b_train, \\\n",
    "                                εz_a=εz_a_train, εz_b=εz_b_train)\n",
    "        grads = tape.gradient(loss_op, trainable_variables_list)\n",
    "        optimizer.apply_gradients(zip(grads, trainable_variables_list))\n",
    "        \n",
    "    # Just run the model if the remainder of i/TRAIN_STEP_INTERVAL != 0\n",
    "    else:\n",
    "        ξ0, μ0, c0, k1, y1_a, z1_a, r1_a, w1_a, ξ1_a, μ1_a, c1_a, k2_a, \\\n",
    "            y1_b, z1_b, r1_b, w1_b, ξ1_b, μ1_b, c1_b, k2_b, loss_op , Residual1, Residual2 = \\\n",
    "        run_model(w0=w_train, y0=y_train, z0=z_train, εy_a=εy_a_train, εy_b=εy_b_train, \\\n",
    "                            εz_a=εz_a_train, εz_b=εz_b_train)\n",
    "\n",
    "    loss_vals[i] = loss_op\n",
    "    w_train = w1_a\n",
    "    y_train = y1_a\n",
    "    z_train = z1_a\n",
    "\n",
    "    # Print losses if the remainer of the division of i by DISPLAY_STEP is 0\n",
    "    if i % DISPLAY_STEP == 0:    \n",
    "        print(f\"Loss at {i}: {loss_op.numpy()} (Residual1={Residual1.numpy()}, Residual2={Residual2.numpy()})\")\n",
    "\n",
    "# Stop timer\n",
    "time_elapsed = time.time() - start\n",
    "\n",
    "print(\"Training took\", time_elapsed, \"seconds.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision-rule plot run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    }
   ],
   "source": [
    "# Make a plot of decision rules\n",
    "DECISION_RULE_PLOT_POINTS = 100\n",
    "DECISION_RULE_Y_REALIZATIONS = 7 # CHANGE NAME TO Y\n",
    "\n",
    "def dim(x, i): # Add dimension to x at axis i helper function\n",
    "    return np.expand_dims(x, axis=i)\n",
    "\n",
    "# Use the first batch\n",
    "batch_number = 0\n",
    "w = w_train[batch_number]\n",
    "y = y_train[batch_number]\n",
    "z = z_train[batch_number]\n",
    "\n",
    "# Repeat k for all plot points\n",
    "w = np.repeat(dim(dim(w, 0), 0), DECISION_RULE_PLOT_POINTS, axis=0) \n",
    "# Set the first agent's wealth to evenly spaced values between w_min and w_max\n",
    "w[:, :, 0] = dim(np.linspace(w_min, w_max, DECISION_RULE_PLOT_POINTS), 1)\n",
    "# Repeat k for all theta realizations\n",
    "w = np.repeat(w, DECISION_RULE_Y_REALIZATIONS, axis=1)\n",
    "\n",
    "# Repeat theta for all theta realizations\n",
    "y = np.repeat(dim(y, 0), DECISION_RULE_Y_REALIZATIONS, axis=0) \n",
    "# Set the first agent's theta to evenly spaced values between THETA_LOW and THETA_HIGH\n",
    "y[:, 0] = np.linspace(y_min, y_max, DECISION_RULE_Y_REALIZATIONS)\n",
    "\n",
    "# Repeat atheta for all theta realizations\n",
    "z = np.repeat(dim(z, 0), DECISION_RULE_Y_REALIZATIONS, axis=0)\n",
    "\n",
    "# Will store our results\n",
    "decision_rule_results = {\n",
    "    \"w0\": np.empty(shape=(DECISION_RULE_PLOT_POINTS, DECISION_RULE_Y_REALIZATIONS, AGENTS)),\n",
    "    \"w1\": np.empty(shape=(DECISION_RULE_PLOT_POINTS, DECISION_RULE_Y_REALIZATIONS, AGENTS)),\n",
    "    \"c0\": np.empty(shape=(DECISION_RULE_PLOT_POINTS, DECISION_RULE_Y_REALIZATIONS, AGENTS)),\n",
    "    \"k1\": np.empty(shape=(DECISION_RULE_PLOT_POINTS, DECISION_RULE_Y_REALIZATIONS, AGENTS)),\n",
    "}\n",
    "\n",
    "def generate_εy_constant(required_batch_size):\n",
    "    return tf.cast(tf.zeros((required_batch_size, AGENTS)), dtype=tf.float32)\n",
    "\n",
    "def generate_εz_constant(required_batch_size):\n",
    "    return tf.cast(tf.zeros((required_batch_size, 1)), dtype=tf.float32)\n",
    "\n",
    "for step in range(DECISION_RULE_PLOT_POINTS):\n",
    "\n",
    "    εy_a = generate_εy_constant(DECISION_RULE_Y_REALIZATIONS)\n",
    "    εz_a = generate_εz_constant(DECISION_RULE_Y_REALIZATIONS)\n",
    "    \n",
    "    # Underscore means we don't care about the value\n",
    "    _, _, c0, k1, _, _, _, w1_a, _, _, _, _, _, _, _, _, _, _, _, _, _ , _, _ = \\\n",
    "        run_model(w0=w[step], y0=y, z0=z, εy_a=εy_a, εy_b=εy_a, \\\n",
    "                            εz_a=εz_a, εz_b=εz_a)\n",
    "    \n",
    "    # Save it\n",
    "    decision_rule_results[\"w0\"][step] = w[step]\n",
    "    decision_rule_results[\"w1\"][step] = w1_a\n",
    "    decision_rule_results[\"c0\"][step] = c0\n",
    "    decision_rule_results[\"k1\"][step] = k1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation plot run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_a` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εy_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`εz_b` is not a valid node name. Accepted names conform to Regex /re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\\\\\\\/>-]*$')/\n"
     ]
    }
   ],
   "source": [
    "SIMULATION_BATCH_SIZE = 1 # BATCH_SIZE\n",
    "SIMULATION_TIME_PERIODS = 1000\n",
    "\n",
    "# Take only as many as we need\n",
    "w = w_train[:SIMULATION_BATCH_SIZE]\n",
    "y = y_train[:SIMULATION_BATCH_SIZE]\n",
    "z = z_train[:SIMULATION_BATCH_SIZE]\n",
    "\n",
    "# Same as generate_εy and generate_εz but does not cast to tensorflow\n",
    "def generate_εy_numpy(required_batch_size):\n",
    "    return np.reshape(np.random.normal(mean_y, σ_y, required_batch_size*AGENTS), (required_batch_size, AGENTS))\n",
    "        # generate shocks to y\n",
    "    \n",
    "def generate_εz_numpy(required_batch_size):\n",
    "    return np.reshape(np.random.normal(mean_z, σ_z, required_batch_size), (required_batch_size, 1))\n",
    "        # generate shocks to z\n",
    "\n",
    "# Restore shocks from file\n",
    "try:\n",
    "    with open(\"one.pkl\", \"rb\") as f:\n",
    "        restored_shocks = pickle.load(f)\n",
    "except:\n",
    "    restored_shocks = {\n",
    "        \"εy\": np.reshape(np.expand_dims(np.random.normal(0, 1, SIMULATION_TIME_PERIODS*AGENTS), axis=1), newshape=(SIMULATION_TIME_PERIODS, AGENTS)),\n",
    "        \"εz\": np.expand_dims(np.random.normal(0, 1, SIMULATION_TIME_PERIODS), axis=1)\n",
    "    }\n",
    "    \n",
    "restored_εy = restored_shocks[\"εy\"][:, :AGENTS]*σ_y+mean_y\n",
    "restored_εz = restored_shocks[\"εz\"][:, :AGENTS]*σ_z+mean_z\n",
    "\n",
    "\n",
    "simulation_results = { # Initial place where we will put results\n",
    "    \"k\": np.empty(shape=(SIMULATION_TIME_PERIODS, SIMULATION_BATCH_SIZE, AGENTS)),\n",
    "    \"c\": np.empty(shape=(SIMULATION_TIME_PERIODS, SIMULATION_BATCH_SIZE, AGENTS)),\n",
    "    \"w\": np.empty(shape=(SIMULATION_TIME_PERIODS, SIMULATION_BATCH_SIZE, AGENTS)),\n",
    "    \"y\": np.empty(shape=(SIMULATION_TIME_PERIODS, SIMULATION_BATCH_SIZE, AGENTS)),\n",
    "    \"z\": np.empty(shape=(SIMULATION_TIME_PERIODS, SIMULATION_BATCH_SIZE, 1)),\n",
    "}\n",
    "\n",
    "for step in range(SIMULATION_TIME_PERIODS):\n",
    "    # Generate shocks\n",
    "    εy_simulation = generate_εy_numpy(SIMULATION_BATCH_SIZE)\n",
    "    εz_simulation = generate_εz_numpy(SIMULATION_BATCH_SIZE)\n",
    "    \n",
    "    # For batch zero, use shocks provided in file\n",
    "    εy_simulation[0] = restored_εy[step]\n",
    "    εz_simulation[0] = restored_εz[step]\n",
    "    \n",
    "    εy_simulation = tf.cast(εy_simulation, tf.float32)\n",
    "    εz_simulation = tf.cast(εz_simulation, tf.float32)\n",
    "    \n",
    "    w0=w\n",
    "    y0=y\n",
    "    z0=z\n",
    "    \n",
    "    _, _, c0, k1, y1_a, z1_a, _, w1_a, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _ = \\\n",
    "    run_model(w0=w0, y0=y0, z0=z0, εy_a=εy_simulation, εy_b=εy_simulation, \\\n",
    "                        εz_a=εz_simulation, εz_b=εz_simulation)  \n",
    "    \n",
    "    # Save it\n",
    "    simulation_results[\"k\"][step]=k1\n",
    "    simulation_results[\"c\"][step]=c0\n",
    "    simulation_results[\"w\"][step]=w0\n",
    "    simulation_results[\"y\"][step]=y0\n",
    "    simulation_results[\"z\"][step]=z0\n",
    "        \n",
    "    # Transition\n",
    "    w = w1_a\n",
    "    y = y1_a\n",
    "    z = z1_a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting parameters \n",
    "plt.rcParams['agg.path.chunksize'] = 100000\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 18\n",
    "\n",
    "# Columns and rows in graph\n",
    "rows = 1\n",
    "cols = 3\n",
    "    \n",
    "# Width, height automatically set\n",
    "height = 5*rows\n",
    "width = 7*cols\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(width)\n",
    "fig.set_figheight(height)\n",
    "\n",
    "# Plot Learning Losses\n",
    "ax = plt.subplot(rows, cols, 1)\n",
    "_ = plt.plot(loss_vals)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "ax.title.set_text(\"Log losses\")\n",
    "\n",
    "counter = 2\n",
    "\n",
    "ax = plt.subplot(rows, cols, 2)\n",
    "for i in range(decision_rule_results[\"c0\"].shape[1]):\n",
    "    plt.plot(decision_rule_results[\"w0\"][:, i, 0], decision_rule_results[\"c0\"][:, i, 0])\n",
    "ax.title.set_text(\"Consumption rule\")\n",
    "\n",
    "ax = plt.subplot(rows, cols, 3)\n",
    "start = 200\n",
    "end = 400\n",
    "drawn_agents = 5\n",
    "for i in range(min(5, simulation_results[\"k\"].shape[2])):\n",
    "    plt.plot(simulation_results[\"k\"][start:end+1, 0, i]) # DRAW ONLY BATCH N = 0\n",
    "if simulation_results[\"k\"].shape[2] != 1: # Plot mean if more than one line was drawn\n",
    "    plt.plot(np.mean(simulation_results[\"k\"][start:end+1, 0], axis=1), linewidth=5.0) # DRAW ONLY BATCH N = 0\n",
    "ax.title.set_text(\"Capital simulation\")\n",
    "try:\n",
    "    plt.savefig('./figures/newFigure.png', bbox_inches='tight')\n",
    "except:\n",
    "    plt.savefig('../../figures/newFigure.png', bbox_inches='tight')\n",
    "    pass\n",
    "# If it doesn't show up, open it manually in the figures directory\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
